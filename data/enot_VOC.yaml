# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
# PASCAL VOC dataset http://host.robots.ox.ac.uk/pascal/VOC
# Example usage: python train.py --data VOC.yaml
# parent
# ‚îú‚îÄ‚îÄ yolov5
# ‚îî‚îÄ‚îÄ datasets
#     ‚îî‚îÄ‚îÄ VOC  ‚Üê downloads here


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/VOC
train: train.txt  # train images (relative to 'path')  16551 images
tune: train.txt  # train images (relative to 'path')  16551 images
pretrain: pretrain.txt  # pretrain images (relative to 'path') 113287 images - search space pre-training
search: search.txt  # search images (relative to 'path') 5000 images - optimal architecture selection
val: val.txt  # val images (relative to 'path')  4952 images
test: val.txt  # test images (optional)

# Classes
nc: 20  # number of classes
names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',
        'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']  # class names


# Download script/URL (optional) ---------------------------------------------------------------------------------------
download: |
  import os
  import xml.etree.ElementTree as ET

  from tqdm import tqdm
  from utils.general import download, Path
  from utils.prepare_to_nas import generate_enot_split


  def convert_label(path, lb_path, year, image_id):
      def convert_box(size, box):
          dw, dh = 1. / size[0], 1. / size[1]
          x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]
          return x * dw, y * dh, w * dw, h * dh

      in_file = open(path / f'VOC{year}/Annotations/{image_id}.xml')
      out_file = open(lb_path, 'w')
      tree = ET.parse(in_file)
      root = tree.getroot()
      size = root.find('size')
      w = int(size.find('width').text)
      h = int(size.find('height').text)

      for obj in root.iter('object'):
          cls = obj.find('name').text
          if cls in yaml['names'] and not int(obj.find('difficult').text) == 1:
              xmlbox = obj.find('bndbox')
              bb = convert_box((w, h), [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')])
              cls_id = yaml['names'].index(cls)  # class id
              out_file.write(" ".join([str(a) for a in (cls_id, *bb)]) + '\n')


  # Download
  dir = Path(yaml['path'])  # dataset root dir
  url = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/'
  urls = [url + 'VOCtrainval_06-Nov-2007.zip',  # 446MB, 5012 images
          url + 'VOCtest_06-Nov-2007.zip',  # 438MB, 4953 images
          url + 'VOCtrainval_11-May-2012.zip']  # 1.95GB, 17126 images
  download(urls, dir=dir / 'images', delete=False)

  # Convert
  path = dir / f'images/VOCdevkit'
  for year, image_set in ('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test'):
      imgs_path = dir / 'images' / f'{image_set}{year}'
      lbs_path = dir / 'labels' / f'{image_set}{year}'
      imgs_path.mkdir(exist_ok=True, parents=True)
      lbs_path.mkdir(exist_ok=True, parents=True)

      image_ids = open(path / f'VOC{year}/ImageSets/Main/{image_set}.txt').read().strip().split()
      for id in tqdm(image_ids, desc=f'{image_set}{year}'):
          f = path / f'VOC{year}/JPEGImages/{id}.jpg'  # old img path
          lb_path = (lbs_path / f.name).with_suffix('.txt')  # new label path
          f.rename(imgs_path / f.name)  # move image
          convert_label(path, lb_path, year, id)  # convert labels to YOLO format

  # Download
  dir = Path(yaml['path'])  # dataset root dir
  url = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/'
  urls = [url + 'VOCtrainval_06-Nov-2007.zip',  # 446MB, 5012 images
          url + 'VOCtest_06-Nov-2007.zip',  # 438MB, 4953 images
          url + 'VOCtrainval_11-May-2012.zip']  # 1.95GB, 17126 images
  train_image_folders = ['images/train2012', 'images/train2007', 'images/val2012', 'images/val2007']
  train_image_paths = [sorted(list((dir / folder).glob('*'))) for folder in train_image_folders]
  train_image_paths = [str(path) for folder_paths in train_image_paths for path in folder_paths]
  train_image_paths = ['./' + os.path.relpath(path, dir) for path in train_image_paths]
  with open(dir / 'train.txt', 'w') as f:
      f.write('\n'.join(train_image_paths))

  test_image_paths = sorted(list((dir / 'images/test2007').glob('*')))
  test_image_paths = [str(path) for path in test_image_paths]
  test_image_paths = ['./' + os.path.relpath(path, dir) for path in test_image_paths]
  with open(dir / 'val.txt', 'w') as f:
      f.write('\n'.join(test_image_paths))

  generate_enot_split(
      dir,
      os.path.relpath(yaml['train'], dir),
      os.path.relpath(yaml['val'], dir),
      n_search=1000,
      seed=0,
  )  # add enot stages data splits
